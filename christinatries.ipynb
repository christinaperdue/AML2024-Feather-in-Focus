{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2735c935",
   "metadata": {
    "id": "2735c935"
   },
   "source": [
    "<h1><center> Group Assignment: Bird Classifier  </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd0b3ce3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "error",
     "timestamp": 1694776892897,
     "user": {
      "displayName": "York Pudds (Yorkie)",
      "userId": "15802187727162843994"
     },
     "user_tz": -120
    },
    "id": "cd0b3ce3",
    "outputId": "da1cfd65-38c1-4971-dd05-c2a17ce22140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available. Running on Apple GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS backend is available. Running on Apple GPU.\")\n",
    "else:\n",
    "    print(\"MPS backend is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60e54e04",
   "metadata": {
    "id": "60e54e04",
    "outputId": "2dda9a07-4c8b-4e52-e8a0-744f58857013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on MPS: tensor([1., 2., 3.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")  # Use MPS for Apple Silicon\n",
    "x = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "print(\"Tensor on MPS:\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4105b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes Array Shape: (200, 312)\n",
      "Sample Attributes: [[0.0106384  0.0106384  0.00709227 ... 0.00918617 0.02526198 0.02066889]\n",
      " [0.         0.01133243 0.00944369 ... 0.00266542 0.02132333 0.05863916]\n",
      " [0.         0.         0.00742474 ... 0.         0.00885258 0.01770516]\n",
      " [0.         0.         0.00386105 ... 0.00683957 0.03647772 0.04331729]\n",
      " [0.         0.03508838 0.         ... 0.0027513  0.01513216 0.15819981]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parse the attributes.txt file\n",
    "attribute_map = {}\n",
    "with open('data/attributes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(' ', 1)  # Split at the first space\n",
    "        if len(parts) == 2:\n",
    "            attr_id, attr_desc = parts\n",
    "            attribute_map[int(attr_id)] = attr_desc\n",
    "\n",
    "# Load attributes.npy\n",
    "attributes_array = np.load('data/attributes.npy')\n",
    "\n",
    "# Example: Print the shape and a sample\n",
    "print(\"Attributes Array Shape:\", attributes_array.shape)\n",
    "print(\"Sample Attributes:\", attributes_array[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b55dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    data/train_images/1.jpg\n",
      "1    data/train_images/2.jpg\n",
      "2    data/train_images/3.jpg\n",
      "3    data/train_images/4.jpg\n",
      "4    data/train_images/5.jpg\n",
      "Name: image_path, dtype: object\n",
      "data/train_images/1.jpg exists: True\n",
      "data/train_images/2.jpg exists: True\n",
      "data/train_images/3.jpg exists: True\n",
      "data/train_images/4.jpg exists: True\n",
      "data/train_images/5.jpg exists: True\n",
      "[  0   0   0 ... 199 199 199]\n",
      "                image_path  label    attr_0    attr_1    attr_2    attr_3  \\\n",
      "0  data/train_images/1.jpg      0  0.010638  0.010638  0.007092  0.003546   \n",
      "1  data/train_images/2.jpg      0  0.000000  0.011332  0.009444  0.000000   \n",
      "2  data/train_images/3.jpg      0  0.000000  0.000000  0.007425  0.000000   \n",
      "3  data/train_images/4.jpg      0  0.000000  0.000000  0.003861  0.000000   \n",
      "4  data/train_images/5.jpg      0  0.000000  0.035088  0.000000  0.000000   \n",
      "\n",
      "     attr_4    attr_5    attr_6    attr_7  ...  attr_302  attr_303  attr_304  \\\n",
      "0  0.138299  0.065603  0.000000  0.005319  ...  0.000000  0.005439  0.005439   \n",
      "1  0.202095  0.041552  0.015110  0.005666  ...  0.006291  0.000000  0.111144   \n",
      "2  0.002475  0.000000  0.000000  0.074247  ...  0.000000  0.000000  0.190411   \n",
      "3  0.003861  0.013514  0.005792  0.073360  ...  0.004885  0.000000  0.190531   \n",
      "4  0.000000  0.000000  0.102458  0.070177  ...  0.000000  0.000000  0.204036   \n",
      "\n",
      "   attr_305  attr_306  attr_307  attr_308  attr_309  attr_310  attr_311  \n",
      "0  0.228446  0.000000  0.000000  0.186020  0.009186  0.025262  0.020669  \n",
      "1  0.008388  0.000000  0.046135  0.202572  0.002665  0.021323  0.058639  \n",
      "2  0.012555  0.000000  0.010462  0.203609  0.000000  0.008853  0.017705  \n",
      "3  0.000000  0.000000  0.000000  0.152750  0.006840  0.036478  0.043317  \n",
      "4  0.002458  0.002458  0.000000  0.031640  0.002751  0.015132  0.158200  \n",
      "\n",
      "[5 rows x 314 columns]\n",
      "3926\n",
      "200\n",
      "3926\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Read and preprocess the CSV\n",
    "data = pd.read_csv('data/train_images.csv')\n",
    "\n",
    "# Prepend 'data' to paths if not already present\n",
    "data['image_path'] = data['image_path'].apply(lambda x: f\"data{x}\" if not x.startswith(\"data\") else x)\n",
    "\n",
    "# Verify the first few paths\n",
    "print(data['image_path'].head())\n",
    "\n",
    "# Check if files exist\n",
    "for path in data['image_path'].head():\n",
    "    print(f\"{path} exists: {os.path.exists(path)}\")\n",
    "\n",
    "# Step 2: Define a PyTorch Dataset \n",
    "# import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        #self.attributes = attributes  # This should be a list or array matching label indices\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        image = image.convert(\"RGB\")  # Ensure 3 channels (RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Get the corresponding attribute for the label\n",
    "        #attribute = self.attributes[label - 1]  # Assuming labels are 1-indexed\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Grayscale(num_output_channels=3),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomRotation(10),\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "image_paths = data['image_path'].values\n",
    "labels = data['label'].values - 1  # Ensure labels are zero-indexed (0 to 199)\n",
    "print(labels)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming 'image_paths' and 'labels' from your dataset\n",
    "data_df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Add attributes to the DataFrame\n",
    "attribute_df = pd.DataFrame(attributes_array, columns=[f\"attr_{i}\" for i in range(attributes_array.shape[1])])\n",
    "data_df = pd.concat([data_df, attribute_df], axis=1)\n",
    "\n",
    "# Example: Check combined data\n",
    "print(data_df.head())\n",
    "\n",
    "\n",
    "# dataset = CombinedDataset(image_paths, attributes_array, labels, transform=transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create training and validation datasets using the CombinedDataset class\n",
    "train_dataset = CombinedDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = CombinedDataset(X_val, y_val, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(len(image_paths))\n",
    "print(len(attributes_array))\n",
    "print(len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a848bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class BirdClassificationModel(nn.Module):\n",
    "    def __init__(self, num_image_features, num_classes):\n",
    "        super(BirdClassificationModel, self).__init__()\n",
    "        \n",
    "        # CNN for image features (e.g., using ResNet18)\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Identity()  # Remove the final classification layer\n",
    "\n",
    "        # Fully connected layers for attributes\n",
    "        # self.fc_attributes = nn.Sequential(\n",
    "        #     nn.Linear(num_attributes, 512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.5)\n",
    "        # )\n",
    "        \n",
    "        # Final classification layer that combines image features and attribute features\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(num_image_features, 256),  # Assuming CNN output and attribute features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)  # Final output layer for classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        # Extract image features\n",
    "        image_features = self.cnn(image)\n",
    "        \n",
    "        # Process attribute features\n",
    "        # attribute_features = self.fc_attributes(attribute)\n",
    "        \n",
    "        # Combine image features and attribute features\n",
    "        # combined_features = torch.cat((image_features), dim=1)\n",
    "        \n",
    "        # Classify combined features\n",
    "        out = self.fc_combined(image_features)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0913087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.7833\n",
      "Validation Loss: 0.6729\n",
      "Validation Accuracy: 11.20%\n",
      "Epoch 2/10\n",
      "Train Loss: 0.4740\n",
      "Validation Loss: 0.4535\n",
      "Validation Accuracy: 14.12%\n",
      "Epoch 3/10\n",
      "Train Loss: 0.2252\n",
      "Validation Loss: 0.3820\n",
      "Validation Accuracy: 15.52%\n",
      "Epoch 4/10\n",
      "Train Loss: 0.1138\n",
      "Validation Loss: 0.4187\n",
      "Validation Accuracy: 15.78%\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0793\n",
      "Validation Loss: 0.3772\n",
      "Validation Accuracy: 15.27%\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0447\n",
      "Validation Loss: 0.4211\n",
      "Validation Accuracy: 13.74%\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0618\n",
      "Validation Loss: 0.4553\n",
      "Validation Accuracy: 14.38%\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0752\n",
      "Validation Loss: 0.4337\n",
      "Validation Accuracy: 14.63%\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0564\n",
      "Validation Loss: 0.4647\n",
      "Validation Accuracy: 13.99%\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0875\n",
      "Validation Loss: 0.5135\n",
      "Validation Accuracy: 12.34%\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "num_image_features = 512  # Output of ResNet18 after the final layer (512)\n",
    "# num_attributes = attributes_array.shape[1]  # 312 if attributes have shape (N, 312)\n",
    "num_classes = len(set(labels))  # Number of unique classes\n",
    "model = BirdClassificationModel(num_image_features, num_classes).to(device)\n",
    "\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# labels = np.array(labels)\n",
    "# print(len(np.unique(labels))) \n",
    "\n",
    "# # Compute class weights\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Use weighted loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:  # Assuming 'dataloader' is correctly set up\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "\n",
    "        # Forward pass: pass both images and attributes to the model\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # _, predicted = torch.max(outputs, 1)\n",
    "        # total += labels.size(0)\n",
    "        # correct += (predicted == labels).sum().item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # epoch_loss = running_loss / len(dataloader)\n",
    "    # epoch_accuracy = 100 * correct / total\n",
    "    # print(f\"Epoch {epoch + 1}/10, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    print(f\"Epoch {epoch + 1}/{10}\")\n",
    "    print(f\"Train Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}\")\n",
    "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d666f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image names: 4000\n",
      "Number of predictions: 4000\n",
      "Predictions have been saved to 'predicted_labels.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Step 2: Load the test dataset using ImageFolder\n",
    "test_dir = 'data/test_images'  # Path to your test image directory\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # No shuffle for evaluation\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "predictions = []  # To store predictions\n",
    "image_names = []  # To store image file names\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for images, _ in test_loader:\n",
    "        # Extract image file names from the dataset\n",
    "        batch_file_names = [\n",
    "            os.path.splitext(os.path.basename(test_loader.dataset.samples[i][0]))[0] \n",
    "            for i in range(len(image_names), len(image_names) + len(images))\n",
    "        ]\n",
    "        image_names.extend(batch_file_names)\n",
    "\n",
    "        images = images.to(device).float()  # Ensure images are float32\n",
    "        \n",
    "        # Model prediction\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Collect predictions (on CPU)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Debugging lengths\n",
    "print(f\"Number of image names: {len(image_names)}\")\n",
    "print(f\"Number of predictions: {len(predictions)}\")\n",
    "\n",
    "# Combine image names and predictions into a DataFrame\n",
    "if len(image_names) != len(predictions):\n",
    "    print(f\"Mismatch detected: {len(image_names)} image names, {len(predictions)} predictions\")\n",
    "else:\n",
    "    predicted_labels = pd.DataFrame({\n",
    "        'id': image_names,\n",
    "        'label': predictions\n",
    "    })\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    predicted_labels.to_csv('predicted_labels.csv', index=False)\n",
    "    print(\"Predictions have been saved to 'predicted_labels.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73619ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
